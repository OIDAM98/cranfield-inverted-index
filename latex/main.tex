%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Lachaise Assignment
% LaTeX Template
% Version 1.0 (26/6/2018)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Marion Lachaise & François Févotte
% Vel (vel@LaTeXTemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\input{structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{LIS4031: Project \#1} % Title of the assignment
\title{Boolean Retrieval Model} % Title of the assignment

\author{Dulio Paolo Caggiano Amand\\ \texttt{dulio.caggianoad@udlap.mx}} % Author name and email address
\author{Oscar Ivan de Alva Martinez\\ \texttt{oscar.dealvamez@udlap.mx}} % Author name and email address

\date{Universidad de las Am\'ericas  Puebla --- \today} % University, school and/or department name(s) and a date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\section*{Introduction} % Unnumbered section

In this practice, a research and development focused on the boolean information retrieval model was carried out to define the basic concepts of a retrieval model. Through the development of this project, a dictionary and a posting list were used to implement an inverted index based on the Cranfield collection.

For the implementation of this project, the programming language Scala was used because it provides a concise notation that allows the creation of a Domain Specific Language (DSL) for the ability to solve the problem. Also, Scala has a tight compatibility and interoperability with Java, that allows to take advantage of both the JVM and the libraries of Java. Furthermore, its strict type system has the advantage of allowing the creation of specific types that model the solution of this problem.

% Math equation/formula
\begin{equation}
	I = \int_{a}^{b} f(x) \; \text{d}x.
\end{equation}

\begin{info} % Information block
	This is an interesting piece of information, to which the reader should pay special attention. Fusce varius orci ac magna dapibus porttitor. In tempor leo a neque bibendum sollicitudin. Nulla pretium fermentum nisi, eget sodales magna facilisis eu. Praesent aliquet nulla ut bibendum lacinia. Donec vel mauris vulputate, commodo ligula ut, egestas orci. Suspendisse commodo odio sed hendrerit lobortis. Donec finibus eros erat, vel ornare enim mattis et.
\end{info}

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\section{Boolean Retrieval Model} % Numbered section

The cranfield collection is based on three main components, the first component is a collection of documents which contains information from different investigations. The second component is the one that contains a set of specific queries for the aforementioned data collection and the third component contains the relevance judgments which are all the factors that are taken to categorize a document as relevant.

The documents contained in the cranfield collection generally maintain a structure, where the information contained in the document is specified by means of headings, some examples can be it ".I" to describe the documents ID or ".A" to list the authors. 

%------------------------------------------------

\subsection{Parsing the collection}

To transform the words found in the documents, a dedicated parser was created to perform the tokenization of these. This parser has the functionality of creating tokens from the headers established within each document, which allows establishing metadata, in the form of classes, for the words found. 

Also, specific classes were created for the documentation of words and metadata, and a class was established to store the content of a document. These classes represent the different types of header found within the document, these are: document number, author, title, affiliation, and abstract text.

On the other hand, the internal structure of a document was established as a list of parsed headers. This is because the documents within the collection do not have a defined structure, which makes it difficult to represent them with only 3one. 

In order to parse the words, the file was first divided into its documents, which are specified at the beginning with the .I header followed by the document number. This is to allow the identification of the words inside each document easier. Then, each document is divided into the sections previously mentioned, which are identified by the headings. A, .T, .B and .W along with the document number where they are located. Finally, these elements are stored within the Document class to indicate that a document from the collection was parsed along with its contents. 

% Numbered question, with subquestions in an enumerate environment
\begin{question}
	Quisque ullamcorper placerat ipsum. Cras nibh. Morbi vel justo vitae lacus tincidunt ultrices. Lorem ipsum dolor sit amet, consectetuer adipiscing elit.

	% Subquestions numbered with letters
	\begin{enumerate}[(a)]
		\item Do this.
		\item Do that.
		\item Do something else.
	\end{enumerate}
\end{question}
	
%------------------------------------------------

\subsection{Inverted Index}

The dictionary was implemented by using an inverted index which give mainly the advantage of access time once you search for a word. The keys used in the dictionary were all the different words found in the documents  and the values are divided in a tuple, with the first element representing the number of occurrences that the word has in all the processed documents and the second element is a set which contains the IDs of the documents in which the word is found, a set is used to avoid the repetition of IDs.

Once the whole file is parsed and the words are tokenized, the list of tokens is processed element by element, adding them to the inverted index. When adding an element to the inverted index, if the index already have that word, the occurrence counter is increased and the document id is added to the set.

\begin{center}
	\begin{minipage}{0.5\linewidth} % Adjust the minipage width to accomodate for the length of algorithm lines
		\begin{algorithm}[H]
			\KwIn{$(a, b)$, two floating-point numbers}  % Algorithm inputs
			\KwResult{$(c, d)$, such that $a+b = c + d$} % Algorithm outputs/results
			\medskip
			\If{$\vert b\vert > \vert a\vert$}{
				exchange $a$ and $b$ \;
			}
			$c \leftarrow a + b$ \;
			$z \leftarrow c - a$ \;
			$d \leftarrow b - z$ \;
			{\bf return} $(c,d)$ \;
			\caption{\texttt{FastTwoSum}} % Algorithm name
			\label{alg:fastTwoSum}   % optional label to refer to
		\end{algorithm}
	\end{minipage}
\end{center}


\subsection{Parsing the query}

To parse the query that the user enters in the program, a free context grammar was used based on the grammar used to solve basic algebraic operations. This is because the operators dealing with the model function works the same as the basic mathematical operators of +, * and - of a scale. This grammar is as follows:

\begin{align*}
	Expr   & ::= Term (\text{'OR'} Term)*                           \\
	Term   & ::= Factor (\text{'AND'} Factor)*                      \\
	Factor & ::= [\text{'NOT'}] (Word | \text{'('} Expr \text{')'}) \\
	Word   & ::= [a-zA-Z]
\end{align*}

This allows to be able to analyze a query through the precedence of the AND, OR and NOT operators, as well as the parentheses. To make the parsing of the query we used the library of Scala Parser Combinators, which allows us to represent in code a grammar free of context and program the cases of these. The parser is in charge of identifying the specified grammar cases and asking the Boolean Retrieval Model to carry out the specified operation. 

\subsection{Boolean Retrieval Model}

When the words are parsed inside the query, they are transformed into a BinaryArray class, which is an array of shorts of the size of the number of processed documents, which limits the data you can use in the array to 0 and 1 to represent in a binary way the occurrence of the words in the documents, representing with a 1 in the position i if the element is in the document i and if it is not found it will be represented with a 0. 

After each word is represented as a BinaryArray, if the query contains the key words AND, OR or NOT, the corresponding binary operation is performed between two of the arrays, based on the precedence of operations previously defined in the parser of the query. The resulting array from performing the binary operations, will be the result of the query, described in the indexes where a 1 is maintained, as the ID of the document that is considered relevant for the search. 


% Numbered question, with an optional title
\begin{question}[\itshape (with optional title)]
	In congue risus leo, in gravida enim viverra id. Donec eros mauris, bibendum vel dui at, tempor commodo augue. In vel lobortis lacus. Nam ornare ullamcorper mauris vel molestie. Maecenas vehicula ornare turpis, vitae fringilla orci consectetur vel. Nam pulvinar justo nec neque egestas tristique. Donec ac dolor at libero congue varius sed vitae lectus. Donec et tristique nulla, sit amet scelerisque orci. Maecenas a vestibulum lectus, vitae gravida nulla. Proin eget volutpat orci. Morbi eu aliquet turpis. Vivamus molestie urna quis tempor tristique. Proin hendrerit sem nec tempor sollicitudin.
\end{question}

%----------------------------------------------------------------------------------------
%	PROBLEM 2
%----------------------------------------------------------------------------------------

\section{Conclusions}

Through out the project, the steps for the creation of a retrieval model were identified and developed. In the same way, the impact of the data structures and the importance that they have within the development of a retrieval model were observed, finally the methods to parse of the documents and queries to obtain and process information from external sources with the implications that they entail were analyzed.

% File contents
\begin{file}[hello.py]
\begin{lstlisting}[language=Python]
#! /usr/bin/python

import sys
sys.stdout.write("Hello World!\n")
\end{lstlisting}
\end{file}

% Command-line "screenshot"
\begin{commandline}
	\begin{verbatim}
		$ chmod +x hello.py
		$ ./hello.py

		Hello World!
	\end{verbatim}
\end{commandline}

% Warning text, with a custom title
\begin{warn}[Notice:]
  In congue risus leo, in gravida enim viverra id. Donec eros mauris, bibendum vel dui at, tempor commodo augue. In vel lobortis lacus. Nam ornare ullamcorper mauris vel molestie. Maecenas vehicula ornare turpis, vitae fringilla orci consectetur vel. Nam pulvinar justo nec neque egestas tristique. Donec ac dolor at libero congue varius sed vitae lectus. Donec et tristique nulla, sit amet scelerisque orci. Maecenas a vestibulum lectus, vitae gravida nulla. Proin eget volutpat orci. Morbi eu aliquet turpis. Vivamus molestie urna quis tempor tristique. Proin hendrerit sem nec tempor sollicitudin.
\end{warn}

%----------------------------------------------------------------------------------------

\end{document}
